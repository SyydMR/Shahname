{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01d5d99-f6bf-44cb-b2cb-fbe3ef1006e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e5e7bf-4a92-45d4-b128-aa4733b24b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'archive/shahname.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88c1da5-60cd-4fd7-b6ac-ca3ae1534440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "text = []\n",
    "with open(base_dir, 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    header = next(csvreader)\n",
    "    for row in csvreader:\n",
    "        text.append(row[4])\n",
    "\n",
    "\n",
    "text = [sub.replace('\\xa0', ' ') for sub in text]\n",
    "text = [sub.replace('\\u200c', ' ') for sub in text]\n",
    "text = [sub.replace('آ', 'ا') for sub in text]\n",
    "text = [sub.replace('َ', '') for sub in text]\n",
    "text = [sub.replace('ُ', '') for sub in text]\n",
    "text = [sub.replace('ِ', '') for sub in text]\n",
    "text = [sub.replace('ة', 'ه') for sub in text]\n",
    "text = [sub.replace('هٔ', 'ه') for sub in text]\n",
    "text = [sub.replace('ك', 'ک') for sub in text]\n",
    "text = [sub.replace('ئ', 'ی') for sub in text]\n",
    "text = [sub.replace('؛', '') for sub in text]\n",
    "text = [sub.replace('ّ', '') for sub in text]\n",
    "text = [sub.replace('ْ', '') for sub in text]\n",
    "text = [sub.replace('،', '') for sub in text]\n",
    "text = [sub.replace('ء', '') for sub in text]\n",
    "text = [sub.replace('«', '') for sub in text]\n",
    "text = [sub.replace('»', '') for sub in text]\n",
    "text = [sub.replace('أ', 'ا') for sub in text]\n",
    "text = [sub.replace(')', '') for sub in text]\n",
    "text = [sub.replace('(', '') for sub in text]\n",
    "text = [sub.replace('ؤ', 'و') for sub in text]\n",
    "\n",
    "\n",
    "text = \" \".join(text[0:(len(text) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e4659e-9b17-4378-aa27-097c60111c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba5f52f-332e-4a21-8e2e-de6e9b526f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45d065b-a892-479a-b809-9e985ad57fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd7b2cb-a07f-4eef-8f6f-57f4655d8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba34871-85cc-4393-bdaa-7ab242902ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند' ---- characters mapped to int ---- > [ 5 28  0 27  4 26  0 10 11  4 29 27 11]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f001906a-ee08-4b30-a7a7-7bc24f74d858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 28,  0, ..., 13, 36, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a96bc1-b23a-42d2-99dc-4e7ca8eb8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ب\n",
      "ه\n",
      " \n",
      "ن\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83ba2be-8de5-498a-a839-4b045042380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد خداوند نام و خداوند جای خداوند روزی ده رهنمای خدا'\n",
      "***************\n",
      "'وند کیوان و گردان سپهر فروزنده ماه و ناهید و مهر ز نام و نشان و گمان برتر است نگارنده بر شده پیکر است'\n",
      "***************\n",
      "' به بینندگان افریننده را نبینی مرنجان دو بیننده را نیابد بدو نیز اندیشه راه که او برتر از نام و از جا'\n",
      "***************\n",
      "'یگاه سخن هر چه زین گوهران بگذرد نیابد بدو راه جان و خرد خرد گر سخن برگزیند همی همان را گزیند که بیند '\n",
      "***************\n",
      "'همی ستودن نداند کس او را چو هست میان بندگی را ببایدت بست خرد را و جان را همی سنجد اوی در اندیشه سخته '\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print(\"***\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c29501-4f89-4cab-8c7b-931d3b5ebb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4cede1-b963-460c-b593-53b6b86936f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'به نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد خداوند نام و خداوند جای خداوند روزی ده رهنمای خد'\n",
      "Target data: 'ه نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد خداوند نام و خداوند جای خداوند روزی ده رهنمای خدا'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6436eaf6-2240-4b05-9ac0-12d25c32d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 5 ('ب')\n",
      "  expected output: 28 ('ه')\n",
      "Step    1\n",
      "  input: 28 ('ه')\n",
      "  expected output: 0 (' ')\n",
      "Step    2\n",
      "  input: 0 (' ')\n",
      "  expected output: 27 ('ن')\n",
      "Step    3\n",
      "  input: 27 ('ن')\n",
      "  expected output: 4 ('ا')\n",
      "Step    4\n",
      "  input: 4 ('ا')\n",
      "  expected output: 26 ('م')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6bc0f8c-39b4-47d8-a0f0-ec5b6a64065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(32, 100), dtype=tf.int64, name=None), TensorSpec(shape=(32, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f929d4aa-e2a1-4921-ac96-a0af260c2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 25\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8288a8a7-3b79-4197-a642-7578e5183d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9707157-7fbb-4a73-8501-9b3eb8b72d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd5e6fd-bee5-429f-a88b-b7b13fadaac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 330ms/step\n",
      "(32, 100, 37) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model.predict(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fac2da39-b490-4f29-8927-8a4f4a7330e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (32, None, 25)            925       \n",
      "                                                                 \n",
      " gru (GRU)                   (32, None, 1024)          3228672   \n",
      "                                                                 \n",
      " dense (Dense)               (32, None, 37)            37925     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3267522 (12.46 MB)\n",
      "Trainable params: 3267522 (12.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6cbbbfd-3999-48dc-9e2d-5ca542f2f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b2cdde-478a-41fb-95ed-8f1ba19d93f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 29, 29, 25,  4, 12, 12, 31,  0,  2,  5,  4, 27, 36, 11, 26,  8,\n",
       "       18,  5, 24, 20,  1, 21, 33, 30, 33,  3, 30, 18, 12,  6, 22, 12, 31,\n",
       "       28, 21, 21, 24, 23, 26, 33, 21, 22, 32,  8,  6, 33, 34, 31,  2, 12,\n",
       "       32, 20, 20, 12,  9, 13, 10,  0, 31,  7,  2,  6,  9, 33, 35, 21, 22,\n",
       "       13, 10,  5,  3, 30, 15, 28, 22, 22,  3,  4,  1,  6, 27,  3, 36, 10,\n",
       "        9, 19,  6,  4, 21, 31,  1,  0, 29, 35, 21,  7, 15, 10,  9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ada50b67-bc59-4f5d-b370-768f56636dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'به نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد خداوند نام و خداوند جای خداوند روزی ده رهنمای خد'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'لوولاذذپ :بانیدمجضبقظ!عژيژ؟يضذتغذپهععقفمژعغچجتژکپ:ذچظظذحرخ پث:تحژگعغرخب؟يسهغغ؟ا!تن؟یخحطتاعپ! وگعثسخح'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "620461f2-d092-4285-bf2a-06f869379dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c54cd97-e237-45eb-83be-06d6374082e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dc34ae8-f678-45a2-abc6-824f16e4a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_CharLevel'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "098df970-360e-4909-b69b-ab34744adcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717781304.899004   55082 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792/792 [==============================] - 37s 45ms/step - loss: 2.2083\n",
      "Epoch 2/20\n",
      "792/792 [==============================] - 35s 45ms/step - loss: 1.6419\n",
      "Epoch 3/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.4578\n",
      "Epoch 4/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.3580\n",
      "Epoch 5/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.2870\n",
      "Epoch 6/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.2260\n",
      "Epoch 7/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.1714\n",
      "Epoch 8/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.1254\n",
      "Epoch 9/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0904\n",
      "Epoch 10/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0709\n",
      "Epoch 11/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0542\n",
      "Epoch 12/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0404\n",
      "Epoch 13/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0336\n",
      "Epoch 14/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0287\n",
      "Epoch 15/20\n",
      "792/792 [==============================] - 36s 45ms/step - loss: 1.0258\n",
      "Epoch 16/20\n",
      "792/792 [==============================] - 36s 46ms/step - loss: 1.0244\n",
      "Epoch 17/20\n",
      "792/792 [==============================] - 36s 46ms/step - loss: 1.0273\n",
      "Epoch 18/20\n",
      "792/792 [==============================] - 36s 46ms/step - loss: 1.0251\n",
      "Epoch 19/20\n",
      "792/792 [==============================] - 37s 46ms/step - loss: 1.0187\n",
      "Epoch 20/20\n",
      "792/792 [==============================] - 37s 46ms/step - loss: 1.0189\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36e6e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_checkpoints = './training_checkpoints_CharLevel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "234ce848-021e-4ba0-9a7f-89a026d775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(training_checkpoints))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c6e0deb-73d4-4f81-91c0-5893f243667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (1, None, 25)             925       \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (1, None, 1024)           3228672   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (1, None, 37)             37925     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3267522 (12.46 MB)\n",
      "Trainable params: 3267522 (12.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d5dfd40-0aad-495b-bbcd-663b4b0652b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  num_generate = 1000\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      predictions = predictions\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c860b6b5-6b6f-4f49-9142-3920e45e01d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سلام خوبی بخواهد سپاه و بمرد همیشه تو و هشت در سرت بد که مارم تهی شاه را خواند پیش بدید ان بد و نه شوی نی گوی بدادش می اید و دست بدی به شاهی و از هر دری دیده بود بدو گفت شاها چنین جنگشان کنم هر درین شهر تن پرگزند نباید که یزدان بود نام اوی مران برگزینم بر تاجو سرگرفتی دهد داد و دین و دل را به هر انجمن تو را ای سخنها فراز ارمید همه برفزند از جهان تاج و شمشید جوی سواری و مهرین چو امد بجای به نزد خردمند نزداشت جای گروه روان و جوانان ایران سپاه هم نفرود بپوشد ز جای بزرگان به رنج که یزدان شاهان خورشیدگار ز دینار و دالش گرامی تنست به یزدان کنیم اندر ارندگان نه ان بخت را بس کن ازاد نا اگهی که ارام یاقوت برکش سوار دریغ ایدم و از روزگار بیفشاند کام و اند چو نشچیر تازه به مادر بگوش چنان خست بیشی ز دیبای روم به دیدار چینی درش کرده انداختی دو دیده پر از خون  و رخسموه دید ز اندیشه دل پرددید ن به ایران سپاه اندرست این سخن به زر زاید و هر مهتران ز پیونده روزگار کهن به چنمست همداستان که شد روز بشمر زنی دولبست ولیکن تر از و نان شمشیرزن سر سینه اندر دل هید رای به خشنود یکسر چنان رنج راست بر شاه ایران به داور دان\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"سلام خوبی\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b13b1-1261-4447-b134-5066060593cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
