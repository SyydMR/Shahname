{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a895f946-a14d-4379-95a3-96415eb30fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34afd0c9-27cd-48f7-a3dd-b2d65bd16011",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'archive/shahname.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97835286-3f50-46d7-8d9d-3e1f0b774e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "text = []\n",
    "with open(base_dir, 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    header = next(csvreader)\n",
    "    for row in csvreader:\n",
    "        text.append(row[4])\n",
    "\n",
    "\n",
    "text = [sub.replace('\\xa0', ' ') for sub in text]\n",
    "text = [sub.replace('\\u200c', ' ') for sub in text]\n",
    "text = [sub.replace('آ', 'ا') for sub in text]\n",
    "text = [sub.replace('َ', '') for sub in text]\n",
    "text = [sub.replace('ُ', '') for sub in text]\n",
    "text = [sub.replace('ِ', '') for sub in text]\n",
    "text = [sub.replace('ة', 'ه') for sub in text]\n",
    "text = [sub.replace('هٔ', 'ه') for sub in text]\n",
    "text = [sub.replace('ك', 'ک') for sub in text]\n",
    "text = [sub.replace('ئ', 'ی') for sub in text]\n",
    "text = [sub.replace('؛', '') for sub in text]\n",
    "text = [sub.replace('ّ', '') for sub in text]\n",
    "text = [sub.replace('ْ', '') for sub in text]\n",
    "text = [sub.replace('،', '') for sub in text]\n",
    "text = [sub.replace('ء', '') for sub in text]\n",
    "text = [sub.replace('«', '') for sub in text]\n",
    "text = [sub.replace('»', '') for sub in text]\n",
    "text = [sub.replace('أ', 'ا') for sub in text]\n",
    "text = [sub.replace(')', '') for sub in text]\n",
    "text = [sub.replace('(', '') for sub in text]\n",
    "text = [sub.replace('ؤ', 'و') for sub in text]\n",
    "text = [sub.replace('؟', '') for sub in text]\n",
    "text = [sub.replace('!', '') for sub in text]\n",
    "text = [sub.replace(':', '') for sub in text]\n",
    "text = [sub.replace('ي', 'ی') for sub in text]\n",
    "\n",
    "text = \" \".join(text[0:(len(text) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a56949-dbea-4f01-afcc-6a02ae945cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "vocab = tokenizer.word_index\n",
    "reversed_dict = {}\n",
    "for key, value in vocab.items():\n",
    "    reversed_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274d99f6-04d1-4090-afb4-48ae51279af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3002fe92-7a10-41b6-9039-dc6fbab456da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([vocab[word] for word in text.split(' ') if word != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b92e85c-caf4-4481-a519-5a9b37ff92db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   78,  364,  113,    1,   99,  140,   25,  670,  219,    6,\n",
       "       2395,  364])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c400b2-c765-4d49-986c-753f562928e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به\n",
      "نام\n",
      "خداوند\n",
      "جان\n",
      "و\n",
      "خرد\n",
      "کز\n",
      "این\n",
      "برتر\n",
      "اندیشه\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "for i in char_dataset.take(10):\n",
    "    print(reversed_dict[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e2e24e2-2a3f-4991-af60-5dc031091d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند جان و خرد کز این برتر اندیشه بر'\n",
      "***************\n",
      "'نگذرد خداوند نام و خداوند جای خداوند روزی ده رهنمای خداوند'\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "for item in sequences.take(2):\n",
    "    chars = [reversed_dict[int(i)] for i in item.numpy()]\n",
    "    print(repr(' '.join(chars)))\n",
    "    print(\"***\" * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51dd02e-0a8e-467f-a5c3-a925aa1a31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12e3540-29f3-4b04-9247-bfb53037bfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(10,), dtype=tf.int64, name=None), TensorSpec(shape=(10,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a8d29b-3f9d-47a5-a4bb-0448383f06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: \n",
      "'به نام خداوند جان و خرد کز این برتر اندیشه'\n",
      "Target data:\n",
      "'نام خداوند جان و خرد کز این برتر اندیشه بر'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ')\n",
    "    words = [reversed_dict[int(i)] for i in input_example.numpy()]\n",
    "    print(repr(' '.join(words)))\n",
    "    print ('Target data:')\n",
    "    words = [reversed_dict[int(i)] for i in target_example.numpy()]\n",
    "    print(repr(' '.join(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01afe89-59d2-4a12-a0a6-37b0d929cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(32, 10), dtype=tf.int64, name=None), TensorSpec(shape=(32, 10), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f55cd6-d8f7-4bc0-9f69-ca80e6497245",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 50\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aae3d60-a600-4229-91b9-811b45a1679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68efcab-265c-4fcd-90a0-c60b28656f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31825965-b053-47a6-b0b9-58297d39f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step\n",
      "(32, 10, 16862) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model.predict(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4b43f8-984c-411e-9002-0aee98520b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (32, None, 50)            843100    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (32, None, 1024)          4403200   \n",
      "                                                                 \n",
      " dense (Dense)               (32, None, 16862)         17283550  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22529850 (85.94 MB)\n",
      "Trainable params: 22529850 (85.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "185f664c-84d7-463a-b756-02eadc796814",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4221068e-f1e3-48c8-b9b9-abfabd78c433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5128,  5201, 10879, 15791,  3937,  7601, 14318,  5974,  7011,\n",
       "       13822])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1fdd6a-d852-4d68-90ec-0bc0132071e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند جان و خرد کز این برتر اندیشه'\n",
      "'دوکدان جادوپرست کاسپم پرنداوری براشفته بهرمزد جرنگ گزیدم ازاددل خوردشان'\n"
     ]
    }
   ],
   "source": [
    "words = [reversed_dict[int(i)] for i in input_example_batch[0].numpy()]\n",
    "print(repr(' '.join(words)))\n",
    "\n",
    "words = [reversed_dict[int(i)] for i in sampled_indices]\n",
    "print(repr(' '.join(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f275ece7-830c-40a4-9fd5-4bf9517efa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bd6a549-8aba-48b2-93f1-39c2f0285379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a44d5b-04d1-4ee9-bc08-498363aa296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_WordLevel'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8b2daf-77bf-4309-90fe-fde9cc339614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717782487.808257   57880 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630/1630 [==============================] - 72s 43ms/step - loss: 6.7598\n",
      "Epoch 2/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 5.9985\n",
      "Epoch 3/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 5.4692\n",
      "Epoch 4/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 5.0258\n",
      "Epoch 5/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 4.6058\n",
      "Epoch 6/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 4.2176\n",
      "Epoch 7/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 3.8835\n",
      "Epoch 8/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 3.5970\n",
      "Epoch 9/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 3.3547\n",
      "Epoch 10/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 3.1422\n",
      "Epoch 11/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.9626\n",
      "Epoch 12/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.8266\n",
      "Epoch 13/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.6923\n",
      "Epoch 14/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.5645\n",
      "Epoch 15/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.4360\n",
      "Epoch 16/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.3302\n",
      "Epoch 17/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.2421\n",
      "Epoch 18/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.1611\n",
      "Epoch 19/20\n",
      "1630/1630 [==============================] - 64s 39ms/step - loss: 2.0807\n",
      "Epoch 20/20\n",
      "1630/1630 [==============================] - 65s 40ms/step - loss: 2.0115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "515e6fdf-eefb-4cf5-abf7-ca26d634feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_checkpoints = './training_checkpoints_WordLevel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f748398d-4b7d-4d1e-973d-8e284053075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(training_checkpoints))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a3b04b3-108b-4c1d-9c1f-3aa2ae4b0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 100\n",
    "    input_eval = [vocab[s] for s in start_string.split(' ')]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(reversed_dict[predicted_id])\n",
    "    return (start_string + ' ' + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f487b421-cc65-441c-92e2-a0c0d99341ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سلام تدبیر نگارش چنویی دستور چوخشنود فروریختند یازد زودی ز افراسیاب بیاورد زاغ اندر امد به گردش بهشت کمان را هزار همی رخش گویی بروبر دراز یکی گفت ایدر شما از خدای به نخچیر گردی و گردنکشان بماند ازیشان تو این با تو داشتم اگر صد و پولاد بیرون مده به اشتاد فرمود تا تیره شد هم به نزدیک شهر چنین است با فر یزدان نگه کرد نیز یکی انک بر سر و مهتر کنند تو با من خرد باد زین چنین مدار از کهان و مهان برین رنج شادست و شمشیر زن ز هر بد که بد نامدار کزو جنگ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"سلام\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac5f51-69f5-4311-845f-533a71263a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
